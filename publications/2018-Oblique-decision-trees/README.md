# Inducing Readable Oblique Decision Trees (2018) #

## Authors ##

- Antonin Leroux, <antonin.leroux@craft.ai>
- Matthieu Boussard, <matthieu@craft.ai>
- Rémi Dès, <remi@craft.ai>

## Abstract ##

Although machine learning models are found in more and more practical applications, stakeholders can be suspicious about the fact that they are not hard-coded and fully specified. To foster trust, it is crucial to provide models whose predictions are explainable. Decision Trees can be understood by humans if they are simple enough, but they suffer in accuracy when compared to other common machine learning methods. Oblique Decision Trees can provide better accuracy and smaller trees, but their decision rules are more complex. This article presents MUST (Multivariate Understandable Statistical Tree), an Oblique Decision Tree split algorithm based on Linear Discriminant Analysis that aims to preserve explainability by limiting the number of variables that appear in decision rules.

Oblique Decision Tree, Decision trees, Explainable AI, Linear discriminant analysis, Machine Learning 
